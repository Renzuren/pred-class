{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABsI3ecGOCz4"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch"
      ],
      "metadata": {
        "id": "_ORVba-uOS84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"email_subjects_dataset_large.csv\")\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "h_u210clOUqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "train_encodings = tokenizer(list(train_df['Subject']), truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
        "\n",
        "test_encodings = tokenizer(list(test_df['Subject']), truncation=True, padding=True, return_tensors='pt', max_length=512)"
      ],
      "metadata": {
        "id": "XRHVbzFFOX1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "train_labels = torch.tensor(label_encoder.fit_transform(list(train_df['Category'])))\n",
        "test_labels = torch.tensor(label_encoder.transform(list(test_df['Category'])))\n",
        "\n",
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
      ],
      "metadata": {
        "id": "l-8ELqjzOZx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(df['Category'].unique()))"
      ],
      "metadata": {
        "id": "beXHxsE8Oehv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        inputs, attention_mask, labels = batch\n",
        "        inputs, attention_mask, labels = inputs.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "aFCQlr2DOgIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        inputs, attention_mask, labels = batch\n",
        "        inputs, attention_mask, labels = inputs.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(all_labels, all_preds))"
      ],
      "metadata": {
        "id": "V6Ec0qmCOhn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'Trained_ESC_dict.pth')"
      ],
      "metadata": {
        "id": "hAMQHNE5UccX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "categories = [\"Technology\", \"Health\", \"Finance\", \"Travel\", \"Food\",\n",
        "              \"Fashion\", \"Sports\", \"Education\", \"Entertainment\", \"Science\",\n",
        "              \"Art\", \"Business\", \"Music\", \"Fitness\", \"Home\",\n",
        "              \"Gaming\", \"Environment\", \"Books\", \"Pets\", \"Movies\",\n",
        "              \"Automotive\", \"Social Media\", \"Career\", \"Shopping\", \"Weather\"]\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model_state_dict = torch.load('/content/WTF.pth')\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(categories))\n",
        "\n",
        "model.load_state_dict(model_state_dict, strict=False)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "input_text = [\"Cars and Carts\", \"PRoduct sales\"]\n",
        "\n",
        "input_encodings = tokenizer (input_text, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(**input_encodings)\n",
        "  logits = outputs.logits\n",
        "  predictions = torch.argmax(logits, dim=1)\n",
        "\n",
        "interpreted_predictions = [categories[prediction.item()] for prediction in predictions]\n",
        "\n",
        "print(\"Predictions:\", interpreted_predictions)"
      ],
      "metadata": {
        "id": "6e2f9ofZVvMw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}